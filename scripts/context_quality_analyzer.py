#!/usr/bin/env python3
"""
ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„ê¸°
í”„ë¡œì íŠ¸ì˜ ì»¨í…ìŠ¤íŠ¸ ì¼ê´€ì„±, ì™„ì„±ë„, ìµœì‹ ì„±ì„ ìë™ ë¶„ì„
"""

import os
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional

class ContextQualityAnalyzer:
    """ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.analysis_results = {}
        
    def analyze_context_hierarchy(self) -> Dict:
        """3ë‹¨ê³„ ì»¨í…ìŠ¤íŠ¸ ê³„ì¸µ ë¶„ì„"""
        hierarchy = {
            "strategic": self._analyze_strategic_context(),
            "tactical": self._analyze_tactical_context(), 
            "operational": self._analyze_operational_context()
        }
        
        return hierarchy
    
    def _analyze_strategic_context(self) -> Dict:
        """ì „ëµì  ì»¨í…ìŠ¤íŠ¸ (project_rules.md) ë¶„ì„"""
        project_rules_paths = [
            self.project_root / "project_rules.md",
            self.project_root / "docs/specs/project_rules.md"
        ]
        
        found_rules = None
        for path in project_rules_paths:
            if path.exists():
                found_rules = path
                break
        
        if not found_rules:
            return {
                "status": "missing",
                "score": 0,
                "issues": ["project_rules.md not found in standard locations"],
                "recommendations": ["Create project_rules.md with core principles"]
            }
        
        # ë‚´ìš© ë¶„ì„
        with open(found_rules, 'r', encoding='utf-8') as f:
            content = f.read()
        
        score = 0
        issues = []
        recommendations = []
        
        # í•„ìˆ˜ ì„¹ì…˜ ì²´í¬
        essential_sections = ["ëª©í‘œ", "ì›ì¹™", "ê·œì¹™", "ê°€ì´ë“œë¼ì¸"]
        present_sections = sum(1 for section in essential_sections if section in content)
        score += (present_sections / len(essential_sections)) * 60
        
        if present_sections < len(essential_sections):
            issues.append(f"í•„ìˆ˜ ì„¹ì…˜ ë¶€ì¡±: {len(essential_sections) - present_sections}ê°œ ëˆ„ë½")
            recommendations.append("ëˆ„ë½ëœ í•„ìˆ˜ ì„¹ì…˜ ì¶”ê°€")
        
        # ë¬¸ì„œ í¬ê¸° ì²´í¬ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ë©´ ì•ˆë¨)
        if len(content) < 500:
            score -= 10
            issues.append("ë¬¸ì„œê°€ ë„ˆë¬´ ê°„ëµí•¨")
            recommendations.append("ìƒì„¸í•œ ê°€ì´ë“œë¼ì¸ ì¶”ê°€")
        elif len(content) > 10000:
            score -= 5
            issues.append("ë¬¸ì„œê°€ ë„ˆë¬´ ì¥í™©í•¨") 
            recommendations.append("í•µì‹¬ ë‚´ìš©ìœ¼ë¡œ ì••ì¶•")
        else:
            score += 20
        
        # ìµœì‹ ì„± ì²´í¬
        mod_time = datetime.fromtimestamp(found_rules.stat().st_mtime)
        days_old = (datetime.now() - mod_time).days
        
        if days_old < 30:
            score += 20
        elif days_old < 90:
            score += 10
            issues.append("ë¬¸ì„œê°€ 90ì¼ ì´ìƒ ì—…ë°ì´íŠ¸ë˜ì§€ ì•ŠìŒ")
            recommendations.append("ìµœì‹  ìƒí™©ì— ë§ê²Œ ì—…ë°ì´íŠ¸")
        else:
            issues.append(f"ë¬¸ì„œê°€ {days_old}ì¼ ë™ì•ˆ ì—…ë°ì´íŠ¸ë˜ì§€ ì•ŠìŒ")
            recommendations.append("ê¸´ê¸‰ ì—…ë°ì´íŠ¸ í•„ìš”")
        
        return {
            "status": "found",
            "path": str(found_rules),
            "score": min(100, max(0, score)),
            "size": len(content),
            "last_modified": mod_time.isoformat(),
            "days_since_update": days_old,
            "issues": issues,
            "recommendations": recommendations
        }
    
    def _analyze_tactical_context(self) -> Dict:
        """ì „ìˆ ì  ì»¨í…ìŠ¤íŠ¸ (CLAUDE.md) ë¶„ì„"""
        claude_md_path = self.project_root / "CLAUDE.md"
        
        if not claude_md_path.exists():
            return {
                "status": "missing",
                "score": 0,
                "issues": ["CLAUDE.md not found"],
                "recommendations": ["Run 'claude init' to generate CLAUDE.md"]
            }
        
        with open(claude_md_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        score = 0
        issues = []
        recommendations = []
        
        # í•„ìˆ˜ ì„¹ì…˜ ì²´í¬
        essential_sections = ["Project Overview", "Structure", "Commands", "Usage"]
        present_sections = sum(1 for section in essential_sections 
                             if section.lower() in content.lower())
        score += (present_sections / len(essential_sections)) * 50
        
        # ë©”íƒ€ë°ì´í„° ì¡´ì¬ ì²´í¬
        if "@meta" in content:
            score += 10
        else:
            issues.append("ë©”íƒ€ë°ì´í„° ëˆ„ë½")
            recommendations.append("ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ê°€")
        
        # Git ìƒíƒœì™€ ë™ê¸°í™” ì²´í¬
        mod_time = datetime.fromtimestamp(claude_md_path.stat().st_mtime)
        git_last_commit = self._get_last_git_commit_time()
        
        if git_last_commit and mod_time >= git_last_commit - timedelta(minutes=5):
            score += 20
            sync_status = "synchronized"
        else:
            score += 5
            sync_status = "outdated"
            issues.append("Git ì»¤ë°‹ê³¼ ë™ê¸°í™”ë˜ì§€ ì•ŠìŒ")
            recommendations.append("claude init ì‹¤í–‰ìœ¼ë¡œ ë™ê¸°í™”")
        
        # í¬ê¸° ì ì •ì„± ì²´í¬
        if 1000 <= len(content) <= 50000:
            score += 20
        else:
            issues.append("ë¬¸ì„œ í¬ê¸° ë¶€ì ì ˆ")
            recommendations.append("ì ì • í¬ê¸°ë¡œ ì¡°ì •")
        
        return {
            "status": "found",
            "path": str(claude_md_path),
            "score": min(100, score),
            "size": len(content),
            "last_modified": mod_time.isoformat(),
            "sync_status": sync_status,
            "issues": issues,
            "recommendations": recommendations
        }
    
    def _analyze_operational_context(self) -> Dict:
        """ìš´ì˜ì  ì»¨í…ìŠ¤íŠ¸ (docs/CURRENT/) ë¶„ì„"""
        current_dir = self.project_root / "docs/CURRENT"
        
        if not current_dir.exists():
            return {
                "status": "missing",
                "score": 0,
                "issues": ["docs/CURRENT/ directory not found"],
                "recommendations": ["Create docs/CURRENT/ directory for active work"]
            }
        
        files = list(current_dir.glob("*.md"))
        
        score = 0
        issues = []
        recommendations = []
        
        # íŒŒì¼ ê°œìˆ˜ ì²´í¬
        if len(files) >= 5:
            score += 30
        elif len(files) >= 2:
            score += 20
        else:
            issues.append(f"í™œì„± ë¬¸ì„œ ë¶€ì¡±: {len(files)}ê°œ")
            recommendations.append("í˜„ì¬ ì‘ì—… ë¬¸ì„œ ì¶”ê°€")
        
        # ìµœì‹ ì„± ì²´í¬
        recent_files = 0
        for file_path in files:
            mod_time = datetime.fromtimestamp(file_path.stat().st_mtime)
            if (datetime.now() - mod_time).days < 7:
                recent_files += 1
        
        if recent_files >= len(files) * 0.5:
            score += 30
        else:
            issues.append("ìµœì‹  ë¬¸ì„œ ë¶€ì¡±")
            recommendations.append("í™œë°œíˆ ê´€ë¦¬ë˜ëŠ” ë¬¸ì„œ ì¦ê°€")
        
        # í•„ìˆ˜ íŒŒì¼ ì²´í¬  
        essential_files = ["status.md", "active-todos.md"]
        present_essential = sum(1 for ef in essential_files 
                              if any(ef in f.name for f in files))
        score += (present_essential / len(essential_files)) * 40
        
        if present_essential < len(essential_files):
            missing = [ef for ef in essential_files 
                      if not any(ef in f.name for f in files)]
            issues.append(f"í•„ìˆ˜ íŒŒì¼ ëˆ„ë½: {', '.join(missing)}")
            recommendations.append("í•„ìˆ˜ íŒŒì¼ ìƒì„±")
        
        return {
            "status": "found",
            "path": str(current_dir),
            "score": min(100, score),
            "file_count": len(files),
            "recent_file_count": recent_files,
            "files": [f.name for f in files],
            "issues": issues,
            "recommendations": recommendations
        }
    
    def _get_last_git_commit_time(self) -> Optional[datetime]:
        """ë§ˆì§€ë§‰ Git ì»¤ë°‹ ì‹œê°„"""
        try:
            import subprocess
            result = subprocess.run(
                ["git", "log", "-1", "--format=%ct"],
                capture_output=True, text=True, cwd=self.project_root
            )
            if result.returncode == 0:
                timestamp = int(result.stdout.strip())
                return datetime.fromtimestamp(timestamp)
        except:
            pass
        return None
    
    def calculate_overall_score(self, hierarchy: Dict) -> Dict:
        """ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        weights = {"strategic": 0.4, "tactical": 0.35, "operational": 0.25}
        
        total_score = 0
        for level, weight in weights.items():
            level_score = hierarchy[level]["score"]
            total_score += level_score * weight
        
        # ë“±ê¸‰ ê³„ì‚°
        if total_score >= 90:
            grade = "A"
            status = "excellent"
        elif total_score >= 80:
            grade = "B"
            status = "good"
        elif total_score >= 70:
            grade = "C"
            status = "acceptable"
        elif total_score >= 60:
            grade = "D"
            status = "needs_improvement"
        else:
            grade = "F"
            status = "critical"
        
        return {
            "total_score": round(total_score, 1),
            "grade": grade,
            "status": status,
            "breakdown": {
                level: {"score": hierarchy[level]["score"], "weight": weight}
                for level, weight in weights.items()
            }
        }
    
    def generate_report(self) -> Dict:
        """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("ğŸ” Analyzing project context quality...")
        
        hierarchy = self.analyze_context_hierarchy()
        overall = self.calculate_overall_score(hierarchy)
        
        # ì „ì²´ ì´ìŠˆ ë° ì¶”ì²œì‚¬í•­ ìˆ˜ì§‘
        all_issues = []
        all_recommendations = []
        
        for level_name, level_data in hierarchy.items():
            for issue in level_data.get("issues", []):
                all_issues.append(f"{level_name.title()}: {issue}")
            for rec in level_data.get("recommendations", []):
                all_recommendations.append(f"{level_name.title()}: {rec}")
        
        report = {
            "analysis_timestamp": datetime.now().isoformat(),
            "project_root": str(self.project_root),
            "overall_quality": overall,
            "context_hierarchy": hierarchy,
            "issues": all_issues,
            "recommendations": all_recommendations,
            "next_actions": self._generate_next_actions(overall, all_issues)
        }
        
        return report
    
    def _generate_next_actions(self, overall: Dict, issues: List[str]) -> List[str]:
        """ë‹¤ìŒ ì•¡ì…˜ ì œì•ˆ"""
        actions = []
        
        if overall["total_score"] < 60:
            actions.append("ğŸš¨ ê¸´ê¸‰: ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¡° êµ¬ì¶•")
        
        if any("missing" in issue.lower() for issue in issues):
            actions.append("ğŸ“ ëˆ„ë½ëœ í•µì‹¬ ë¬¸ì„œ ìƒì„±")
            
        if any("outdated" in issue.lower() or "ì—…ë°ì´íŠ¸" in issue for issue in issues):
            actions.append("ğŸ”„ ê¸°ì¡´ ë¬¸ì„œ ì—…ë°ì´íŠ¸")
            
        if any("ë™ê¸°í™”" in issue for issue in issues):
            actions.append("âš™ï¸ ìë™ ë™ê¸°í™” ì‹œìŠ¤í…œ ì„¤ì •")
            
        return actions
    
    def print_dashboard(self, report: Dict):
        """ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ëŒ€ì‹œë³´ë“œ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š CONTEXT QUALITY DASHBOARD")
        print("="*60)
        
        overall = report["overall_quality"]
        print(f"ğŸ¯ Overall Score: {overall['grade']} ({overall['total_score']}/100)")
        print(f"ğŸ“ˆ Status: {overall['status'].replace('_', ' ').title()}")
        print()
        
        # ê³„ì¸µë³„ ì ìˆ˜
        for level_name, level_data in report["context_hierarchy"].items():
            emoji = {"strategic": "ğŸ¯", "tactical": "âš¡", "operational": "ğŸ”§"}
            print(f"{emoji.get(level_name, 'ğŸ“‹')} {level_name.title()}: "
                  f"{level_data['score']}/100 ({level_data['status']})")
        
        print()
        
        # ì£¼ìš” ì´ìŠˆ
        if report["issues"]:
            print("âš ï¸  Issues Found:")
            for issue in report["issues"][:5]:
                print(f"   â€¢ {issue}")
            if len(report["issues"]) > 5:
                print(f"   ... and {len(report['issues']) - 5} more issues")
            print()
        
        # ë‹¤ìŒ ì•¡ì…˜
        if report["next_actions"]:
            print("ğŸš€ Next Actions:")
            for action in report["next_actions"]:
                print(f"   {action}")
        
        print("="*60)

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    analyzer = ContextQualityAnalyzer()
    report = analyzer.generate_report()
    
    # ëŒ€ì‹œë³´ë“œ ì¶œë ¥
    analyzer.print_dashboard(report)
    
    # ë¦¬í¬íŠ¸ ì €ì¥
    report_path = Path("docs/CURRENT/context-quality-report.json")
    report_path.parent.mkdir(exist_ok=True)
    
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ Detailed report saved to: {report_path}")
    
    # ì ìˆ˜ì— ë”°ë¥¸ exit code
    if report["overall_quality"]["total_score"] < 60:
        return 1
    return 0

if __name__ == "__main__":
    exit(main())